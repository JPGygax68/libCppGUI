- Remove Default_font_mapper.hpp

2016-05-09
==========

I let myself get bogged down by over-thinking this stylesheet business. I'll try to recap before letting the matter rest for now.

- The management of font handles is probably implemented in the wrong place right now, i.e. in the root widget, when it acually belongs with the Canvas (which might delegate it further to a "resource holder" if the graphics resources should be shared with other Canvas instances)

- At this time, colors are described statically, so there is no need for member variables to hold their untranslated values; and since translation is trivial and build-time (constexpr), there is no need to store the translated values either.
  - This will change when stylesheets are introduced. It will make sense then to store the translated value at "style application" time (no need to cache the untranslated value).
  
So, even though at the current time there are resources (i.e. colors) that require neither the untranslated nor the translated value to be store, this situation is temporary, and there is little point trying to use the "members-via-inheritance" trick to work around the waste of space that would otherwise be introduced by the "no zero-sized data members" rule of C++.

What is required though is a specializable template that is capable of holding either untranslated, translated or both handles of a given resource, with hooks for init() and cleanup().

I'm going to spend the next couple of hours implementing this.


2016-05-06
==========

My thinking process regarding stylesheets does not seem to be making real progress. I'll now try to come up with a pragmatic approach that will enable me to continue without getting bogged down by a big re-design. What do I need ?

- Styling parameters (colors, border withs, font parameters) must be defined outside of the code itself (there are many such stopgaps in the current code)

- Some of these parameters must be adapted for use by the subsystems (graphics, sound later on)
  - This happens during init()
    - init() is therefore the opportunity to "kill two birds with one stone": 1) obtain the style definitions (which could be a somewhat involved process once stylesheets finally come into play) 2) obtain the adapted resources (primarily fonts)
      - It also means that style changes would require a cleanup() (yet-to-be introduced opposite of init()) followed by a new execution of init(). This actually looks like a rather elegant compromise (between full CSS-like freedom and lightweight implementation)

- Inheriting style definitions from containers will have to happen, though not necessarily now.

- The same is true of run-time assignable stylesheets - though actually, this is a feature that would usually not be needed at all and that I therefore relegate to low priority.

So, the way forward for now looks like this:

- All style definitions are moved to inheritable methods.
  - These methods can be static or constexpr for now.
  - Later on, these methods will redirect to stylesheets [actually, the support for stylesheets could be encapsulated into aspects, of which there could then be variants with and without stylesheet support]

---

Addendum: self-aware structs (http://duriansoftware.com/joe/Self-aware-struct-like-types-in-C++11.html, though the "self-aware" part may not be needed) might be of use to access resources without caring about whether or not they need adapting (works around the C++ limitation of not supporting 0-sized structs):
  - for each resource:
    - define a struct that has entry points for init() and cleanup() plus an accessor get()
      - init() and cleanup() can be no-ops if the resource does not need translating
      - get() will either be a pass-through or return the handle of the translated resource
    - have the widget class inherit from that struct OR put it into a grouping struct
    
If resource structs are grouped, meta-programming (apply()) can be used for initialization and cleanup


2016-05-05
==========

About styles, again
-------------------

- Is it really necessary/desirable that they can be changed at run-time ?
  - Possible "middle ground": do not allow switching at run-time, but re-generate the UI (possibly using persistency to minimize the impact on the user) ?
  
- Is it desirable to make stylesheets static ?
  - PROs: less run-time costs
  - CONs: types are no longer identical -> unnecessary polymorphism (with an extra inheritance level) would be required to "hide" differences
  
=> Design decision: stylesheets are consulted at run-time (not specifying when exactly yet)

- How / when are stylesheets applied ?
  - Because they can influence layouting, stylesheets are needed when layouting (which may be at design-time or at run-time)
    - This may also mean that some style definitions are not needed in layout-less instantiations, such as padding
    
- Should styles really cascade ? Does it make sense that e.g. the button border width may be defined anywhere in a hierarchy ?
  - While this makes sense in the browser, I'm not convinced it serves a real need in a standard GUI.
    - Example 1: A property panel embedded in a larger UI, where properties are displayed with a smaller font to save space.
      - the font size need only be known at layout time
      - the canvas font handle (NOT the rasterized font) should be inherited from the panel
        -> individual widgets should probably cache the font handle so they don't have to climb the hierarchy to get it
  
- The content of stylesheets should be computed statically, so that the compiler and linker can throw away unneeded stuff.
  - But in order to avoid polymorphism either via virtual methods (run-time bloat) or template parameters on the consumers (which would introduce type incompatibilities between otherwise identical components, see above), the structure of the stylesheets needs to be normalized
    -> Templatized factories producing normalized stylesheet objects (via a constexpr factory method) ?
    
- How to make stylesheets extendable, e.g. to support third-party widgets ?
  - Relatively easily: by deriving. The problem however is when multiple third-party extensions are involved that do not know each other.
    - Each widget defines a struct with the run-time styles it needs
    - 
    
... trailing off ...
  
2016-05-03
==========

A thought about borders: I think I should change the way I used to think about them. Borders are NOT a universal concept to be applied everywhere - I guess that sort of thinking came chiefly from my experience with CSS.

Instead, borders should be used where needed, and only there: around text input fields ("textbox"), list boxes, "combo" boxes, etc. (in fact the presence of the word "box" is a clear indicator of where borders are of use).


2016-05-01
==========

I have made good, if slow, progress on the Listbox these past days. A few things are worth noting:

- take_focus() now propagates upwards, in the sense that if a widget refuses to take the focus, it will still inform its container, so that the container, in turn, may take the focus upon itself (which it should do anyway to put itself in the focus chain).

- There is a need to have visual feedback clearly indicating which widget has the focus. In particular, it is annoying that, even though a listbox can now be (indirectly) focus by clicking on its scrollbar (or any of its children, though with a list of buttons, that cannot be done without clicking one of the buttons), there is no indication that the listbox is now ready to be navigated with the cursor keys.

### Other things to think about

- Exception safety:
  - When is it ok for a widget to throw an exception ? 
  - Can it be ensured that the GUI will stay in a stable state after an exception was thrown ?
  - Callbacks should be upgraded to real events
    - Is there a motivation to use aspects to support both simple callbacks or full-blown signal/slot handling ?
  - What about concurrency ?
    - Must all operations on the GUI be serialized, or is concurrency allowable (and useful) in certain cases ?
      - e.g. a worker thread reporting progress via a progress bar ?
        - typically, the worker thread might change the value of the progress bar, then call invalidate() which would be responsible for queueing a redraw by the main thread
      - loading an image (e.g. for a supposed image viewer widget) and preparing that image for use by the graphics subsystem could be done in a worker thread IF the graphics wrapper supports this (e.g. with OpenGL, a secondary context could be created). If however it does not, then the graphics wrapper should provide a means to bring that operation into the main thread transparently (doable via a lambda, which the compiler can (hopefully) optimise into inline code when deferring is unnecessary)

- States in debug builds ?
  - It may be useful at some point to protect library users (or developers, just as much) from avoidable mistakes by enforcing (in debug builds only) discrete states, with all methods being associated with one or more of those states and only valid for calling when the widget (or entire GUI) is in one of those states. E.g.:
    - defining the user interface (through set_...() methods) may only be done when in "setup" state
    - the "layouting" state is only available if the library is configured to carry that aspect
      - However layouting can still occur for specific widgets if the aspect has been specifically enabled on them. In such a case, however, "layouting" would be a secondary state and concurrent to the GUI's "main" state.
    - init() will put the GUI into "initializing" state (and only be allowed following the "setup" or the "layout" state)
    - event handlers require the "ready" state
      - ? is there a way to prevent loops in event handling ?
        -> probably yes, but not with a state machine - it might involve a lot of "friend" statements instead
    - rendering requires the "drawable" state (which can only be entered via the platform adapter) (actually, the exact interplay between the platform adapter and the library proper will need some thinking about)
    - some states could be thread-local, while most would probably be global (to a given root widget, or even to the whole process)
  
  - Another thought: all adapters (graphics, keyboard, mouse, sound, etc.) should define a method them of state changes. Of course those methods are only allowed to carry out checks - they musn't do any work required in release builds because they won't be called then.
  
  - The state machine would most certainly "live" in the root widget.
  
2016-04-28
==========

First implementation attempt of the Listbox failed (as in "almost worked").

Working on it revealed a problem I had forgotten about: the fact that the thumb cannot usually be perfectly synchronized with the content area it is linked with.

It is therefore important, when moving the thumb by dragging it, that the thumb *movement* be used as input, and NOT its position!

It may also be helpful to "normalize" the thumb's position after a dragging operation has ended - in fact, that would probably be the only way to ensure that the thumb can reliably be moved to either end position.

It may also mean that implementing the Listbox as a specialization of Scrollbox was a bad idea. Though the current implementation of the Scrollbox only has a vertical scrollbar, that will change in the future, while a Listbox usually does not have a horizontal scrollbox; in fact, it would be possible to compute the minimal width of a Listbox on the basis of the widest of its contained items, all but removing the remaining similarities.
  
  -> Q: is there a legitimate use case for a list box with a horizontal scrollbar ? -> YES, thinking about it, this is quite possible
  
Therefore, is it still possible and a good idea to implement Listbox as a derivation of Scrollbox ?

I think the answer is YES: all it really takes is a way to customize the navigation, i.e. to leave it to the concrete implementation to decide by how much to travel when one of the buttons is pushed, the mousewheel is used, the slide range is clicked either before or after the thumb, or the equivalent action is performed via the keyboard.

Touch-based navigation, implementation of which hasn't started yet, is another incentive to have a single implementation.

Instead of derivation, how about using composition ? Let the scrollbox ask its content pane how far to travel, while to scrollbox still does the travelling itself ?

  -> Might work, but what about selecting/focusing/highlighting items ?
    
    -> This must be done using a "bring into view" mechanism, which is quite distinct from scrolling itself:
      - Scrollbox gets input (scrollbar, keyboard) for "up/down one item"
      - Scrollbox sends that input along to its content pane
      - Content pane changes its "selected item", notes its position
      - Content pane tells container scrollbox to "bring into view" rectangle of newly selected item
  
About travelling:

  - With a standard scrollbox, the travelled amount is arbitrary for "single step", while the amount for "page up" / "page down" is simply the visible size (= the inner rect of the scrollbox), possibly minus a configurable "overlap".
  
  - With a listbox, the "single step" is the step from the beginning of the first visible item to the beginning of the next one.
    
Possible approach:

- Scrollable_pane as a specialization of Container, adding the ability to communicate with the scroll box:
  - notify the scrollbox of changes to its size (scrollbox then updates the offset of the pane, and the position of the thumb)

- Grid_pane (or, for the time being, List_pane), as a specialization of Scrollable_pane, adding the abilities:
  - Informing the container (the scrollbox) about the travelling distance for "up" and "down" (separately), which may depend on the height of the first/last item
  
The problem with this is that it requires either unnecessary virtual methods, or two separate specializations of Scrollbox.

An acceptable compromise would be to combine delegated navigation with default navigation, by giving precedence to the former.

To avoid requiring forking Scrollbox, delegated navigation could be introduced in Scrollable_pane as inline no-ops (even constexpr); the concrete type of the content pane could then be injected into Scrollbox as a template parameter.

This appears (and is) somewhat complicated, but does offer the advantage of greater flexibility, and thus less hassle when implementing things like grids and even treeviews later on.

---------

The Scrollbar class is becoming a problem, as one other class to redesign. I believe it is a good strategy to redefine its responsibility now: it should no longer try to keep track of a position by itself (as it does now, in the form of a fraction), but leave that to its client, which will in turn update the position and size of the thumb.

--------------

Idea: implement notification (such as "Position_change" in Scrollbar) as nil-able aspects ?


2016-04-27
==========

There is a need to define an interface between the Scrollbox component and its content.

The current state is working, but treats the content pane as a simple, uniform surface, which can be moved by arbitrary amounts of pixels. This does not take into account the size of items contained in the pane.

What is to be done?

- Implement a completely separate component "Listbox" ? 
  - Or is that name reserved for a component that contains items that are not themselves widgets (indeed typically simple text strings) ?
  
"Listbox":

- A scrollbox combined with a list of widgets

- Those widgets will be arranged into a vertical "stack", the width of each widget set to the "inner width" of the listbox, and its height to the minimum of the highest item (which will get stored to the main aspect and used to configure the scrollbox as well). This will be done as part of the layouting process.
  -> This implies that adding/removing widgets will only be possible if layouting is enabled at least for the Scrollbox component.
  
- Regardless of possible differences in height, each "item widget" counts as a single step navigation-wise

- Layouting of the scrollbox will be based on a configurable number (on the layouter aspect) of "maximum visible items"
  -> NO, that is not possible -> it might be done for get_minimal_size() though

- It is probably best to put the items into a sub-container with "stack" layouting (which may need to be slightly adapted)

2016-04-07
==========

- After implementing Glyph_button, I found that there is currently no way to enforce an aspect ratio, which would make glyph buttons look much nicer.
  -> Future extension ? More sophisticated layouting ?
  
2016-04-05
==========

Working on a text input dialog. Not intended to be reusable yet, except by copy-pasting it into Locsim Instructor.

Several things need work:

- Using MaterialIcons is problematic because apparently the boxing isn't quite correct
  -> THIS APPEARS TO BE WRONG. I've just downloaded and installed a tool called Type Light, and it shows that the MaterialDesign icons are perfectly centered
  -> However, glyphs appear to be systematically shifted by one pixel to the left and the top - but this is actually wrong: the top and left padding is one pixel, where the bottom and right is two pixels - meaning it's impossible at that size to get perfect centering because of grid-fitting.

2016-03-27
==========

- Silly problem: when scrolling with the wheel and the mouse cursor passes onto another child widget without being moved, the highlight does not change until the user actually moves the mouse

2016-03-23
==========

Right now, setting the value of a widget (e.g. "text" on a Textbox) requires a a check (or possibly more later on) to find out whether or not the rasterized font is available.

What is missing at this time is an awareness about whether or not a widget is "live"; or, if maintaining that state turns out to be avoidable, a distinction between *initializing* values versus *updating* them (possibly via overloaded versions of the property setters ?).

I do think, however, that a one-time initialization method is required, to be called after de-serializing or programmatically definining the UI.
If layouting is enabled, the corresponding layout() on the root widget would need to occur immediately before that.

From the above follows a rule:

THE LAYOUT OF A WIDGET *SHOULD NOT* DEPEND ON ITS VALUE (OR SET OF VALUES).

The reason is that this would make it harder to predict the visual appearance of a UI right when it first appears, which is already quite a bit uncertain as soon as font sizes etc. are no longer fixed.

==> TODO: implement:

  1) a virtual method initialize()
  2) property setters that do not trigger invalidation or layout recalculation
      - try to find names that express the difference, rather than employing overloads or prefixed versions of existing names
  
2016-03-14
==========

How to implement trigger_redraw() in a way that will get optimal run-time behaviour on any possible combination of backends ? Brainstorming.

- For a game-type application where frames are redrawn at a high rate independently of GUI interactions, trigger_redraw() could be a no-op
  - Caveat: this does not apply, however, if the GUI is rendered to a dedicated off-screen buffer.
  
- When the only reason to redraw the GUI is in response to user interaction, the best approach is to collect and delay redraw operations until the input event that triggered the need to redraw something has been fully handled.

  - Caveat: the fact that an input event has been fully handled does not necessarily mean that the (partial or full) redraw can or should be done right away. It is conceivable (though probably not very common) that it could happen in another thread. This would make sense if, for example, the GUI is rather complex and rendering it in the same thread as the "event pump" could reduce responsiveness.
  
- For old-style hardware with only 2D acceleration, or when rendering directly to video memory without the help of a GPU (e.g. Linux framebuffer), it can make sense to execute redraws immediately.

- Under the same circumstances, certain operations such as scrolling can be optimized so that only some parts of the affected area need to be redrawn.

- Modern hardware can also help reduce the need to redraw, though in different ways (off-screen buffers / images in video memory ("textures")).

- In rare cases of very low-performance hardware, it could make sense to make redraws interruptible: if filling in an area uncovered by scrolling takes too long, and new input events are already pending, the user experience may be better served by "pushing back" the redraws.

---------------

The above requirements are pretty diverse. It seems important to me that a programmer need not concern himself with all these details, not even when adapting the library for new backends. It is therefore imperative not only to provide abstractions for drawing operations, but also to come up with an impeccable architecture to support said abstractions.

### "Scrolling"

I used the term "scrolling" above, but that is actually a user-space term. "Blitting" was the technical term used for fast transfers of image portions to and from a framebuffer, which is what made scrolling (at reasonable speeds) possible back then. And though such technology is unlikely to come back on PCs, it could be useful on low-power embedded devices.

Contemporary graphical hardware, which is typically 3D-capable, does not need to resort to optimizing image transfers: it has enough memory to store images "whole", and is able to render a whole lot of them at great speed, and at any position.

Supporting these fundamentally different types of hardware requires a higher-level abstraction, so I'm toying with the idea of "virtual spaces".

For example, a listbox could be implemented as a frame that displays a range of "stripes". These stripes would be of fixed height and identified by numbers that would start at 0; however stripes could be added both at the end and before the current first stripe (and possibly inserted anywhere in-between too).

With 2D acceleration (or none), e.g. scrolling down would then translate to "blitting" the bulk of the visibles stripes upward, then triggering a redraw (delayed or not) for the newly uncovered stripe.

With 3D acceleration, the implementation would allocate textures - individually for each strip or, more realistically, of greater size so that each texture could hold several stripes -, and draw the stripes from there.

Caveat: it should be noted that using textures to store the rendered content of list box items would not normally be a worthwhile optimization - though it could be if the rendering is non-trivial. The idea of virtual spaces (1-dimensional in this example) remains valid.

### What's needed

- A draw() method on every widget. Takes into account all state and renders the widget "from scratch".

- A method invalidate() that expresses the need to redraw the widget (by executing draw() as soon as possible)

  - In a game-like rendering loop (without off-screen buffer), invalidate() can be reduced to setting a "dirty" flag.
  
  - The most common case is probably to just delegate to a callback, which is tasked with updating the UI (possibly redrawing layers both
    "below" and "above" the UI)

- All GUI renderer implementations must provide a pair of methods to prepare for and cleaning up after rendering
  
  - This does NOT mean setting the current OpenGL context, which is a platform-specific operation. This must be done by the code, directly called or indirectly triggered by invalidate(), that does the actual rendering.









































