2016-04-28
==========

First implementation attempt of the Listbox failed (as in "almost worked").

Working on it revealed a problem I had forgotten about: the fact that the thumb cannot usually be perfectly synchronized with the content area it is linked with.

It is therefore important, when moving the thumb by dragging it, that the thumb *movement* be used as input, and NOT its position!

It may also be helpful to "normalize" the thumb's position after a dragging operation has ended - in fact, that would probably be the only way to ensure that the thumb can reliably be moved to either end position.

It may also mean that implementing the Listbox as a specialization of Scrollbox was a bad idea. Though the current implementation of the Scrollbox only has a vertical scrollbar, that will change in the future, while a Listbox usually does not have a horizontal scrollbox; in fact, it would be possible to compute the minimal width of a Listbox on the basis of the widest of its contained items, all but removing the remaining similarities.
  
  -> Q: is there a legitimate use case for a list box with a horizontal scrollbar ? -> YES, thinking about it, this is quite possible
  
Therefore, is it still possible and a good idea to implement Listbox as a derivation of Scrollbox ?

I think the answer is YES: all it really takes is a way to customize the navigation, i.e. to leave it to the concrete implementation to decide by how much to travel when one of the buttons is pushed, the mousewheel is used, the slide range is clicked either before or after the thumb, or the equivalent action is performed via the keyboard.

Touch-based navigation, implementation of which hasn't started yet, is another incentive to have a single implementation.

Instead of derivation, how about using composition ? Let the scrollbox ask its content pane how far to travel, while to scrollbox still does the travelling itself ?

  -> Might work, but what about selecting/focusing/highlighting items ?
    
    -> This must be done using a "bring into view" mechanism, which is quite distinct from scrolling itself:
      - Scrollbox gets input (scrollbar, keyboard) for "up/down one item"
      - Scrollbox sends that input along to its content pane
      - Content pane changes its "selected item", notes its position
      - Content pane tells container scrollbox to "bring into view" rectangle of newly selected item
  
About travelling:

  - With a standard scrollbox, the travelled amount is arbitrary for "single step", while the amount for "page up" / "page down" is simply the visible size (= the inner rect of the scrollbox), possibly minus a configurable "overlap".
  
  - With a listbox, the "single step" is the step from the beginning of the first visible item to the beginning of the next one.
    
Possible approach:

- Scrollable_pane as a specialization of Container, adding the ability to communicate with the scroll box:
  - notify the scrollbox of changes to its size (scrollbox then updates the offset of the pane, and the position of the thumb)

- Grid_pane (or, for the time being, List_pane), as a specialization of Scrollable_pane, adding the abilities:
  - Informing the container (the scrollbox) about the travelling distance for "up" and "down" (separately), which may depend on the height of the first/last item
  
The problem with this is that it requires either unnecessary virtual methods, or two separate specializations of Scrollbox.

An acceptable compromise would be to combine delegated navigation with default navigation, by giving precedence to the former.

To avoid requiring forking Scrollbox, delegated navigation could be introduced in Scrollable_pane as inline no-ops (even constexpr); the concrete type of the content pane could then be injected into Scrollbox as a template parameter.

This appears (and is) somewhat complicated, but does offer the advantage of greater flexibility, and thus less hassle when implementing things like grids and even treeviews later on.

---------

The Scrollbar class is becoming a problem, as one other class to redesign. I believe it is a good strategy to redefine its responsibility now: it should no longer try to keep track of a position by itself (as it does now, in the form of a fraction), but leave that to its client, which will in turn update the position and size of the thumb.

--------------

Idea: implement notification (such as "Position_change" in Scrollbar) as nil-able aspects ?


2016-04-27
==========

There is a need to define an interface between the Scrollbox component and its content.

The current state is working, but treats the content pane as a simple, uniform surface, which can be moved by arbitrary amounts of pixels. This does not take into account the size of items contained in the pane.

What is to be done?

- Implement a completely separate component "Listbox" ? 
  - Or is that name reserved for a component that contains items that are not themselves widgets (indeed typically simple text strings) ?
  
"Listbox":

- A scrollbox combined with a list of widgets

- Those widgets will be arranged into a vertical "stack", the width of each widget set to the "inner width" of the listbox, and its height to the minimum of the highest item (which will get stored to the main aspect and used to configure the scrollbox as well). This will be done as part of the layouting process.
  -> This implies that adding/removing widgets will only be possible if layouting is enabled at least for the Scrollbox component.
  
- Regardless of possible differences in height, each "item widget" counts as a single step navigation-wise

- Layouting of the scrollbox will be based on a configurable number (on the layouter aspect) of "maximum visible items"
  -> NO, that is not possible -> it might be done for get_minimal_size() though

- It is probably best to put the items into a sub-container with "stack" layouting (which may need to be slightly adapted)

2016-04-07
==========

- After implementing Glyph_button, I found that there is currently no way to enforce an aspect ratio, which would make glyph buttons look much nicer.
  -> Future extension ? More sophisticated layouting ?
  
2016-04-05
==========

Working on a text input dialog. Not intended to be reusable yet, except by copy-pasting it into Locsim Instructor.

Several things need work:

- Using MaterialIcons is problematic because apparently the boxing isn't quite correct
  -> THIS APPEARS TO BE WRONG. I've just downloaded and installed a tool called Type Light, and it shows that the MaterialDesign icons are perfectly centered
  -> However, glyphs appear to be systematically shifted by one pixel to the left and the top - but this is actually wrong: the top and left padding is one pixel, where the bottom and right is two pixels - meaning it's impossible at that size to get perfect centering because of grid-fitting.

2016-03-27
==========

- Silly problem: when scrolling with the wheel and the mouse cursor passes onto another child widget without being moved, the highlight does not change until the user actually moves the mouse

2016-03-23
==========

Right now, setting the value of a widget (e.g. "text" on a Textbox) requires a a check (or possibly more later on) to find out whether or not the rasterized font is available.

What is missing at this time is an awareness about whether or not a widget is "live"; or, if maintaining that state turns out to be avoidable, a distinction between *initializing* values versus *updating* them (possibly via overloaded versions of the property setters ?).

I do think, however, that a one-time initialization method is required, to be called after de-serializing or programmatically definining the UI.
If layouting is enabled, the corresponding layout() on the root widget would need to occur immediately before that.

From the above follows a rule:

THE LAYOUT OF A WIDGET *SHOULD NOT* DEPEND ON ITS VALUE (OR SET OF VALUES).

The reason is that this would make it harder to predict the visual appearance of a UI right when it first appears, which is already quite a bit uncertain as soon as font sizes etc. are no longer fixed.

==> TODO: implement:

  1) a virtual method initialize()
  2) property setters that do not trigger invalidation or layout recalculation
      - try to find names that express the difference, rather than employing overloads or prefixed versions of existing names
  
2016-03-14
==========

How to implement trigger_redraw() in a way that will get optimal run-time behaviour on any possible combination of backends ? Brainstorming.

- For a game-type application where frames are redrawn at a high rate independently of GUI interactions, trigger_redraw() could be a no-op
  - Caveat: this does not apply, however, if the GUI is rendered to a dedicated off-screen buffer.
  
- When the only reason to redraw the GUI is in response to user interaction, the best approach is to collect and delay redraw operations until the input event that triggered the need to redraw something has been fully handled.

  - Caveat: the fact that an input event has been fully handled does not necessarily mean that the (partial or full) redraw can or should be done right away. It is conceivable (though probably not very common) that it could happen in another thread. This would make sense if, for example, the GUI is rather complex and rendering it in the same thread as the "event pump" could reduce responsiveness.
  
- For old-style hardware with only 2D acceleration, or when rendering directly to video memory without the help of a GPU (e.g. Linux framebuffer), it can make sense to execute redraws immediately.

- Under the same circumstances, certain operations such as scrolling can be optimized so that only some parts of the affected area need to be redrawn.

- Modern hardware can also help reduce the need to redraw, though in different ways (off-screen buffers / images in video memory ("textures")).

- In rare cases of very low-performance hardware, it could make sense to make redraws interruptible: if filling in an area uncovered by scrolling takes too long, and new input events are already pending, the user experience may be better served by "pushing back" the redraws.

---------------

The above requirements are pretty diverse. It seems important to me that a programmer need not concern himself with all these details, not even when adapting the library for new backends. It is therefore imperative not only to provide abstractions for drawing operations, but also to come up with an impeccable architecture to support said abstractions.

### "Scrolling"

I used the term "scrolling" above, but that is actually a user-space term. "Blitting" was the technical term used for fast transfers of image portions to and from a framebuffer, which is what made scrolling (at reasonable speeds) possible back then. And though such technology is unlikely to come back on PCs, it could be useful on low-power embedded devices.

Contemporary graphical hardware, which is typically 3D-capable, does not need to resort to optimizing image transfers: it has enough memory to store images "whole", and is able to render a whole lot of them at great speed, and at any position.

Supporting these fundamentally different types of hardware requires a higher-level abstraction, so I'm toying with the idea of "virtual spaces".

For example, a listbox could be implemented as a frame that displays a range of "stripes". These stripes would be of fixed height and identified by numbers that would start at 0; however stripes could be added both at the end and before the current first stripe (and possibly inserted anywhere in-between too).

With 2D acceleration (or none), e.g. scrolling down would then translate to "blitting" the bulk of the visibles stripes upward, then triggering a redraw (delayed or not) for the newly uncovered stripe.

With 3D acceleration, the implementation would allocate textures - individually for each strip or, more realistically, of greater size so that each texture could hold several stripes -, and draw the stripes from there.

Caveat: it should be noted that using textures to store the rendered content of list box items would not normally be a worthwhile optimization - though it could be if the rendering is non-trivial. The idea of virtual spaces (1-dimensional in this example) remains valid.

### What's needed

- A draw() method on every widget. Takes into account all state and renders the widget "from scratch".

- A method invalidate() that expresses the need to redraw the widget (by executing draw() as soon as possible)

  - In a game-like rendering loop (without off-screen buffer), invalidate() can be reduced to setting a "dirty" flag.
  
  - The most common case is probably to just delegate to a callback, which is tasked with updating the UI (possibly redrawing layers both
    "below" and "above" the UI)

- All GUI renderer implementations must provide a pair of methods to prepare for and cleaning up after rendering
  
  - This does NOT mean setting the current OpenGL context, which is a platform-specific operation. This must be done by the code, directly called or indirectly triggered by invalidate(), that does the actual rendering.









































